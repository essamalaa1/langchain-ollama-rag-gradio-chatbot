{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2da594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Essam\\anaconda3\\envs\\pt-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "# --- Configuration ---\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"7ffdbf28402b8d9ea42603fe9c84e6cb7e963a17ba330bcc120abc8f219b6548\"\n",
    "\n",
    "LLM_MODEL = \"llama3:latest\"\n",
    "EMBEDDING_MODEL = \"nomic-embed-text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c93c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize LLM and Embeddings ---\n",
    "llm = ChatOllama(model=LLM_MODEL, temperature=0.0)\n",
    "embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b87b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Document URLs to Scrape ---\n",
    "LANGCHAIN_DOC_URLS = [\n",
    "    \"https://python.langchain.com/docs/get_started/introduction\",\n",
    "    \"https://python.langchain.com/docs/how_to/migrate_agent/\",\n",
    "    \"https://python.langchain.com/docs/versions/migrating_chains/\",\n",
    "    \"https://python.langchain.com/docs/integrations/llms/ollama\",\n",
    "    \"https://python.langchain.com/docs/integrations/vectorstores/chroma\",\n",
    "    \"https://python.langchain.com/docs/concepts/#llms\",\n",
    "    \"https://python.langchain.com/docs/tutorials/rag/\",\n",
    "    \"https://python.langchain.com/docs/expression_language/\",\n",
    "    \"https://python.langchain.com/docs/integrations/document_loaders/web_base/\",\n",
    "    \"https://python.langchain.com/docs/integrations/tools/searx_search/\",\n",
    "]\n",
    "\n",
    "\n",
    "scraped_docs_dir = \"scraped_langchain_docs\"\n",
    "persist_db_directory = \"langchain_chroma_db_persistent\"\n",
    "collection_name = \"langchain_docs_scraped_persistent_v1\"\n",
    "\n",
    "os.makedirs(scraped_docs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1932df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scraping Function ---\n",
    "def scrape_and_extract_text(url):\n",
    "    print(f\"Scraping: {url}\")\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        resp = requests.get(url, headers=headers, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "        \n",
    "        # Try more specific selectors first\n",
    "        main_content_selectors = [\n",
    "            'article[role=\"main\"]',\n",
    "            'main',\n",
    "            'div.theme-doc-markdown', # Docusaurus\n",
    "            'div[class*=\"markdown\"]',\n",
    "            'div.content',\n",
    "            'article'\n",
    "        ]\n",
    "        main = None\n",
    "        for selector in main_content_selectors:\n",
    "            main = soup.select_one(selector)\n",
    "            if main:\n",
    "                break\n",
    "        \n",
    "        if main:\n",
    "            for tag_selector in ['script', 'style', 'nav', 'footer', 'header', 'aside', '.toc', 'button[class*=\"theme-edit-this-page\"]']:\n",
    "                for tag in main.select(tag_selector):\n",
    "                    tag.decompose()\n",
    "            parts = [p.get_text(separator=' ', strip=True) for p in main.find_all(['h1','h2','h3','h4','p','li','code','pre','td','th'])]\n",
    "            text = \"\\n\\n\".join(filter(None, parts))\n",
    "            if not text.strip() and len(text) < 200: # Fallback for less structured pages\n",
    "                text = main.get_text(separator='\\n', strip=True)\n",
    "        else:\n",
    "            print(f\"  Warning: Could not find a specific main content element for {url}. Using body.\")\n",
    "            for tag in soup(['script','style','nav','footer','header','aside']):\n",
    "                tag.decompose()\n",
    "            text = soup.body.get_text(separator='\\n', strip=True) if soup.body else ''\n",
    "        \n",
    "        print(f\"  Successfully scraped. Text length: {len(text)}\")\n",
    "        return text.strip()\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"  Timeout error scraping {url}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  Request error scraping {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"  Generic error processing {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f5748c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load vector store from: langchain_chroma_db_persistent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Essam\\AppData\\Local\\Temp\\ipykernel_20760\\3292634876.py:9: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded vector store with 203 documents.\n"
     ]
    }
   ],
   "source": [
    "# --- Load or Build Vector Store ---\n",
    "vectorstore = None\n",
    "retriever = None\n",
    "\n",
    "if embeddings:\n",
    "    if os.path.isdir(persist_db_directory) and any(os.scandir(persist_db_directory)):\n",
    "        print(f\"Attempting to load vector store from: {persist_db_directory}\")\n",
    "        try:\n",
    "            vectorstore = Chroma(\n",
    "                persist_directory=persist_db_directory,\n",
    "                embedding_function=embeddings,\n",
    "                collection_name=collection_name\n",
    "            )\n",
    "            if vectorstore._collection.count() > 0:\n",
    "                retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "                print(f\"Successfully loaded vector store with {vectorstore._collection.count()} documents.\")\n",
    "            else:\n",
    "                print(\"Vector store loaded but appears to be empty. Will rebuild.\")\n",
    "                retriever = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading vector store: {e}. Will attempt to rebuild.\")\n",
    "            retriever = None\n",
    "    else:\n",
    "        print(f\"Vector store not found at {persist_db_directory} or is empty. Building new one.\")\n",
    "\n",
    "    if not retriever:\n",
    "        print(\"Building new vector store...\")\n",
    "        docs = []\n",
    "        for i, url in enumerate(LANGCHAIN_DOC_URLS):\n",
    "            # Sanitize filename from URL\n",
    "            sanitized_url_part = re.sub(r'[^a-zA-Z0-9_-]+', '_', url.split(\"//\")[-1])\n",
    "            filename = os.path.join(scraped_docs_dir, f\"doc_{i}_{sanitized_url_part[:50]}.txt\")\n",
    "            text = None\n",
    "            \n",
    "            if os.path.exists(filename):\n",
    "                with open(filename, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read().strip()\n",
    "                if text:\n",
    "                    print(f\"Loaded cached content from {filename}\")\n",
    "                else:\n",
    "                    print(f\"Cached file {filename} is empty. Re-scraping.\")\n",
    "                    text = None\n",
    "            \n",
    "            if not text:\n",
    "                text = scrape_and_extract_text(url)\n",
    "                if text:\n",
    "                    with open(filename, 'w', encoding='utf-8') as f:\n",
    "                        f.write(text)\n",
    "                    print(f\"Saved scraped content to {filename}\")\n",
    "                else:\n",
    "                    print(f\"Failed to scrape or extract text from {url}. Skipping.\")\n",
    "                    continue\n",
    "            \n",
    "            if text:\n",
    "                docs.append(Document(page_content=text, metadata={\"source\": url}))\n",
    "\n",
    "        if docs:\n",
    "            print(f\"Collected {len(docs)} documents for vector store.\")\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "            chunks = splitter.split_documents(docs)\n",
    "            print(f\"Split documents into {len(chunks)} chunks.\")\n",
    "            \n",
    "            try:\n",
    "                vectorstore = Chroma.from_documents(\n",
    "                    documents=chunks,\n",
    "                    embedding=embeddings,\n",
    "                    collection_name=collection_name,\n",
    "                    persist_directory=persist_db_directory\n",
    "                )\n",
    "                vectorstore.persist()\n",
    "                retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "                print(f\"Successfully built and persisted vector store with {vectorstore._collection.count()} chunks.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error building vector store: {e}\")\n",
    "                retriever = None\n",
    "        else:\n",
    "            print(\"No documents were successfully processed to build the vector store.\")\n",
    "            retriever = None\n",
    "else:\n",
    "    print(\"Embeddings not available. Skipping vector store setup.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd8322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build RAG QA Chain ---\n",
    "rag_chain = None\n",
    "if retriever:\n",
    "    rag_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    ")\n",
    "\n",
    "search_utility = SerpAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4f2af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper to get top similarity score ---\n",
    "def get_top_similarity_score(query: str, retriever, k=1) -> float:\n",
    "    try:\n",
    "        docs_and_scores = retriever.vectorstore.similarity_search_with_score(query, k=k)\n",
    "        if docs_and_scores:\n",
    "            _, score = docs_and_scores[0]\n",
    "            return score\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing similarity score: {e}\")\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3392467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_tool_func(query: str, similarity_threshold: float = 0.8) -> str:\n",
    "    if rag_chain and retriever:\n",
    "        try:\n",
    "            # Check similarity score\n",
    "            top_score = get_top_similarity_score(query, retriever)\n",
    "            print(f\"Top similarity score: {top_score}\")\n",
    "            if top_score > similarity_threshold:\n",
    "                raise ValueError(\"Low similarity score — falling back to web search\")\n",
    "\n",
    "            result = rag_chain.invoke({\"query\": query})\n",
    "            answer = result.get(\"result\", \"\").strip()\n",
    "            sources = result.get(\"source_documents\", [])\n",
    "\n",
    "            if answer and sources:\n",
    "                citations = \"\\n\".join(f\"- {doc.metadata.get('source')}\" for doc in sources)\n",
    "                return (\n",
    "                    f\"{answer}\\n\\n\"\n",
    "                    f\"Sources:\\n\"\n",
    "                    f\"{citations}\"\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\"RAG returned no answer or sources\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"RAG fallback reason: {e}\")\n",
    "\n",
    "    try:\n",
    "        web_results = search_utility.run(query)\n",
    "    except Exception as e:\n",
    "        print(f\"WebSearch error: {e}\")\n",
    "        web_results = \"Sorry, I'm unable to perform a web search right now.\"\n",
    "\n",
    "    return (\n",
    "        \"I couldn't find a definitive answer in my local documents, so here's what I found online:\\n\"\n",
    "        f\"{web_results}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89481eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_tool = Tool(\n",
    "    name=\"LangChainDocsQA\",\n",
    "    func=rag_tool_func,\n",
    "    description=\"Ask questions about LangChain internals, code examples, and integrations. Falls back to web search if not found locally.\"\n",
    ")\n",
    "\n",
    "def safe_web_search(query: str) -> str:\n",
    "    try:\n",
    "        return search_utility.run(query)\n",
    "    except Exception as e:\n",
    "        print(f\"WebSearch error: {e}\")\n",
    "        return \"Sorry, I couldn't perform a web search right now.\"\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"WebSearch\",\n",
    "    func=safe_web_search,\n",
    "    description=\"General web search via SerpAPI (with built-in error handling).\"\n",
    ")\n",
    "\n",
    "\n",
    "python_tool = Tool(\n",
    "    name=\"PythonInterpreter\",\n",
    "    func=PythonREPLTool().run,\n",
    "    description=\"Execute Python code for calculations or data manipulations.\"\n",
    ")\n",
    "\n",
    "tools = [rag_tool, search_tool, python_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db517740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Essam\\AppData\\Local\\Temp\\ipykernel_20760\\4148823426.py:16: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "C:\\Users\\Essam\\AppData\\Local\\Temp\\ipykernel_20760\\4148823426.py:17: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent_executor = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# --- Memory & Agent ---\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "system = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "You are an expert assistant that outputs **only** a JSON object in this exact form:\n",
    "\n",
    "```json\n",
    "{\"action\":\"<ToolName>\",\"action_input\":\"<string>\"}\n",
    "action must be one of: LangChainDocsQA, WebSearch, PythonInterpreter, Final Answer\n",
    "action_input must be exactly the string to pass to that tool (no extra quotes, no nested dicts).\n",
    "Do not output any other text.\n",
    "\"\"\")\n",
    "\n",
    "human = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "prompt = ChatPromptTemplate.from_messages([system, human])\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "agent_executor = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    agent_kwargs={\"prompt\": prompt},\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=\"force\",\n",
    "    max_iterations=7,\n",
    "    early_stopping_method=\"generate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c943c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant scores range:   0.4264291524887085 … 0.882327675819397\n",
      "Irrelevant scores range: 0.8145221471786499 … 1.2147629261016846\n",
      "\n",
      "Suggested threshold ≈ (0.882 + 0.815)/2 = 0.848\n",
      "You might use a slightly conservative value, e.g.:\n",
      "    SIMILARITY_THRESHOLD = 0.848\n",
      "\n",
      "Full scores:\n",
      "     label                                                        query    score\n",
      "irrelevant                                  Who won the 2022 World Cup? 1.214763\n",
      "irrelevant                             Who wrote 'Pride and Prejudice'? 1.160347\n",
      "irrelevant                             Symptoms of vitamin D deficiency 1.157709\n",
      "irrelevant                      What's the history of the Eiffel Tower? 1.118858\n",
      "irrelevant                            What is the population of Brazil? 1.115735\n",
      "irrelevant                              What's the capital of Mongolia? 1.112212\n",
      "irrelevant                                   Who painted the Mona Lisa? 1.096067\n",
      "irrelevant                             Latest box office hits this week 1.093750\n",
      "irrelevant                              Best smartphone cameras in 2025 1.088867\n",
      "irrelevant                               Latest trends in hip-hop music 1.088500\n",
      "irrelevant                        How to do a backflip on a skateboard? 1.075318\n",
      "irrelevant                             What is the Pythagorean theorem? 1.065175\n",
      "irrelevant                                  How to plant a rose garden? 1.058667\n",
      "irrelevant                            How to brew the perfect espresso? 1.047737\n",
      "irrelevant                              What causes auroras in the sky? 1.034413\n",
      "irrelevant                 Define quantum entanglement in simple terms. 1.032423\n",
      "irrelevant                              What's the recipe for tiramisu? 0.997652\n",
      "irrelevant                           How to knit a scarf for beginners? 0.958881\n",
      "irrelevant                                  How to solve a Rubik's cube 0.951021\n",
      "  relevant                 What's the role of ConversationBufferMemory? 0.882328\n",
      "  relevant     How do I add source citations in a RetrievalQA response? 0.832627\n",
      "  relevant                  Show me an example of SerpAPIWrapper usage. 0.832381\n",
      "irrelevant                       Explain blockchain in under 100 words. 0.814522\n",
      "  relevant          What is the YAML config for a chat prompt template? 0.812346\n",
      "  relevant    How do I use Docusaurus-style HTML selectors in scraping? 0.808660\n",
      "  relevant                 What's the structure of a RetrievalQA chain? 0.791709\n",
      "  relevant             Explain the `chain_type='stuff'` in RetrievalQA. 0.782296\n",
      "  relevant                How does RecursiveCharacterTextSplitter work? 0.771778\n",
      "  relevant                     How do you chunk documents with overlap? 0.771047\n",
      "  relevant             How to scrape and cache docs before vectorizing? 0.700893\n",
      "  relevant What's the default k in as_retriever(search_kwargs={'k':…})? 0.693877\n",
      "  relevant     Explain AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION. 0.675296\n",
      "  relevant               What does `OllamaEmbeddings(model=…)` produce? 0.663711\n",
      "  relevant       What are the key parameters for Chroma.from_documents? 0.653690\n",
      "  relevant            How to migrate from Chains v0 to v1 in LangChain? 0.601532\n",
      "  relevant           How to call PythonREPLTool from a LangChain agent? 0.574934\n",
      "  relevant         How to handle parsing errors with a LangChain agent? 0.521090\n",
      "  relevant                  How do I build a custom agent in LangChain? 0.511711\n",
      "  relevant                     How can I persist a Chroma vector store? 0.472030\n",
      "  relevant                How do I integrate Ollama LLM with LangChain? 0.426429\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "relevant_qs = [\n",
    "    \"How do I build a custom agent in LangChain?\",\n",
    "    \"What's the structure of a RetrievalQA chain?\",\n",
    "    \"How do I integrate Ollama LLM with LangChain?\",\n",
    "    \"Show me an example of SerpAPIWrapper usage.\",\n",
    "    \"How does RecursiveCharacterTextSplitter work?\",\n",
    "    \"What are the key parameters for Chroma.from_documents?\",\n",
    "    \"Explain the `chain_type='stuff'` in RetrievalQA.\",\n",
    "    \"How can I persist a Chroma vector store?\",\n",
    "    \"How do I add source citations in a RetrievalQA response?\",\n",
    "    \"What's the role of ConversationBufferMemory?\",\n",
    "    \"How to call PythonREPLTool from a LangChain agent?\",\n",
    "    \"What is the YAML config for a chat prompt template?\",\n",
    "    \"How do you chunk documents with overlap?\",\n",
    "    \"Explain AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION.\",\n",
    "    \"How to handle parsing errors with a LangChain agent?\",\n",
    "    \"What's the default k in as_retriever(search_kwargs={'k':…})?\",\n",
    "    \"How to migrate from Chains v0 to v1 in LangChain?\",\n",
    "    \"What does `OllamaEmbeddings(model=…)` produce?\",\n",
    "    \"How to scrape and cache docs before vectorizing?\",\n",
    "    \"How do I use Docusaurus-style HTML selectors in scraping?\"\n",
    "]\n",
    "\n",
    "irrelevant_qs = [\n",
    "    \"Who won the 2022 World Cup?\",\n",
    "    \"What's the recipe for tiramisu?\",\n",
    "    \"Latest trends in hip-hop music\",\n",
    "    \"How to plant a rose garden?\",\n",
    "    \"What's the capital of Mongolia?\",\n",
    "    \"Define quantum entanglement in simple terms.\",\n",
    "    \"Who wrote 'Pride and Prejudice'?\",\n",
    "    \"Best smartphone cameras in 2025\",\n",
    "    \"What is the Pythagorean theorem?\",\n",
    "    \"How to do a backflip on a skateboard?\",\n",
    "    \"Explain blockchain in under 100 words.\",\n",
    "    \"What is the population of Brazil?\",\n",
    "    \"How to brew the perfect espresso?\",\n",
    "    \"Symptoms of vitamin D deficiency\",\n",
    "    \"What causes auroras in the sky?\",\n",
    "    \"How to solve a Rubik's cube\",\n",
    "    \"Who painted the Mona Lisa?\",\n",
    "    \"What's the history of the Eiffel Tower?\",\n",
    "    \"How to knit a scarf for beginners?\",\n",
    "    \"Latest box office hits this week\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for q in relevant_qs:\n",
    "    score = get_top_similarity_score(q, retriever)\n",
    "    rows.append({\"label\": \"relevant\", \"query\": q, \"score\": score})\n",
    "for q in irrelevant_qs:\n",
    "    score = get_top_similarity_score(q, retriever)\n",
    "    rows.append({\"label\": \"irrelevant\", \"query\": q, \"score\": score})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "rel_max = df[df.label==\"relevant\"].score.max()\n",
    "rel_min = df[df.label==\"relevant\"].score.min()\n",
    "irr_max = df[df.label==\"irrelevant\"].score.max()\n",
    "irr_min = df[df.label==\"irrelevant\"].score.min()\n",
    "\n",
    "print(\"Relevant scores range:  \", rel_min, \"…\", rel_max)\n",
    "print(\"Irrelevant scores range:\", irr_min, \"…\", irr_max)\n",
    "\n",
    "midpoint = (rel_max + irr_min) / 2\n",
    "print(f\"\\nSuggested threshold ≈ ({rel_max:.3f} + {irr_min:.3f})/2 = {midpoint:.3f}\")\n",
    "print(\"You might use a slightly conservative value, e.g.:\")\n",
    "print(f\"    SIMILARITY_THRESHOLD = {midpoint:.3f}\")\n",
    "\n",
    "print(\"\\nFull scores:\")\n",
    "print(df.sort_values(by=\"score\", ascending=False).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13112665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Sending query to rag_tool_func (with fallback enabled):\n",
      "Top similarity score: 1.2147629261016846\n",
      "RAG fallback reason: Low similarity score — falling back to web search\n",
      "\n",
      "--- Response ---\n",
      "I couldn't find a definitive answer in my local documents, so here's what I found online:\n",
      "Argentina national football team\n"
     ]
    }
   ],
   "source": [
    "# Fallback test\n",
    "test_query = \"Who won the 2022 World Cup?\"\n",
    "\n",
    "print(\"\\n[TEST] Sending query to rag_tool_func (with fallback enabled):\")\n",
    "response = rag_tool_func(test_query)\n",
    "\n",
    "print(\"\\n--- Response ---\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f2c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Essam\\anaconda3\\envs\\pt-gpu\\lib\\site-packages\\gradio\\chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Essam\\AppData\\Local\\Temp\\ipykernel_20760\\727026499.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  bot_message = agent_executor.run(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHere is my response:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"action\": \"PythonInterpreter\",\n",
      "  \"action_input\": \"sorted([3,2,6,2,8,4,2])\"\n",
      "}\n",
      "```\n",
      "\n",
      "This will execute the Python code to sort the list and return the result.\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The sorted list is: [2, 2, 2, 3, 4, 6, 8]\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"WebSearch\",\n",
      "  \"action_input\": \"Who is the current US President?\"\n",
      "}\n",
      "```\n",
      "\n",
      "(Note: I've used Option 1 to suggest using WebSearch to find the answer)\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mDonald Trump\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The current US President is Donald Trump.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"WebSearch\",\n",
      "  \"action_input\": \"Donald Trump children\"\n",
      "}\n",
      "```\n",
      "\n",
      "Note: I used the WebSearch tool to provide information about Donald Trump's children.\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m[{'title': \"Trump's 'Big, Beautiful Bill' Includes $1,000 'MAGA Accounts' for Kids\", 'link': 'https://www.businessinsider.com/trump-big-beautiful-bill-maga-savings-accounts-children-2025-5', 'source': 'Business Insider', 'source_logo': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada75601a87cbea2d341d234d0a8260611208aa6358f60e4a56f0d.png', 'date': '1 day ago', 'thumbnail': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada756bc4bb8602126b5fe6d4a3e84f0f499d6.jpeg'}, {'title': 'Trump’s ‘Big, Beautiful Bill’ proposal offers ‘MAGA accounts’ with $1K for newborns', 'link': 'https://nypost.com/2025/05/13/us-news/trumps-big-beautiful-bill-includes-maga-accounts-proposal-giving-1k-to-newborns/', 'source': 'New York Post', 'source_logo': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada7566d4f5c54513ec3ab7aad006383067c919294902e955df099.png', 'date': '17 hours ago', 'thumbnail': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada756400a85a9a0610c07fa8b56dfe7e304a6.jpeg'}, {'title': 'Trump’s ‘big beautiful bill’ proposes a MAGA bank account for kids. What does it mean?', 'link': 'https://www.independent.co.uk/news/world/americas/us-politics/trump-tax-bill-maga-children-bank-account-b2750176.html', 'source': 'The Independent', 'source_logo': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada756163e83290d5cfc681052dd2829d401f760e4311b1fee5810.png', 'date': '21 hours ago', 'thumbnail': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada7561bc8dabdc3371470349995b9af4e53a2.jpeg'}, {'title': 'How Much $1,000 MAGA Account for Kids Could Be Worth at 18 Years Old', 'link': 'https://www.newsweek.com/1000-maga-account-kids-could-become-big-18-experts-2071788', 'source': 'Newsweek', 'source_logo': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada75617efd20253bdcc07b830a4b351315da78d54a9c3f84baae7.png', 'date': '15 hours ago', 'thumbnail': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada756de58d36cbd75f0c8fd656b9cc6736686.jpeg'}, {'title': 'Trump-backed tax bill would expand child tax credit, establish ‘MAGA accounts’ for kids', 'link': 'https://www.baltimoresun.com/2025/05/14/trump-backed-tax-bill-would-expand-child-tax-credit-establish-maga-accounts-for-kids/', 'source': 'Baltimore Sun', 'source_logo': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada756f03dcd7a317582d4d3d5126687f21a1721fd1f61a33115c7.png', 'date': '3 hours ago', 'thumbnail': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada756a38f87b7fe4275db1af6f9ac6496400c.jpeg'}, {'title': 'The Trump Administration’s Reckless Policies Will Kill Children', 'link': 'https://newrepublic.com/article/195152/trump-kennedy-pronatalism-children-health', 'source': 'The New Republic', 'source_logo': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada756526dfb70c90147d5e67c1d3182ce1b09f7d3a4ed449891c0.png', 'date': '1 day ago', 'thumbnail': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada756d4b58f0c32984d93796f4ef9689d6836.jpeg'}, {'title': 'Trump humiliated as school kids ask ‘why is he orange’ on trip to Washington', 'link': 'https://www.irishstar.com/news/us-news/trump-humiliated-school-kids-ask-35219409', 'source': 'Irish Star', 'source_logo': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada7562de663823685b38d6d6568e32ec1dadf9df72871de8934d6.png', 'date': '20 hours ago', 'thumbnail': 'https://serpapi.com/searches/682486d3bde979cec2a879a6/images/bd5c888173ada7565f7535bf9402901161c39ce4d312d6e3.jpeg'}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Donald Trump has five children: Donald Trump Jr., Ivanka Trump, Eric Trump, Tiffany Trump, and Barron Trump.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"LangChainDocsQA\",\n",
      "    \"action_input\": \"custom agent\"\n",
      "}\n",
      "```\n",
      "\n",
      "This will ask the user to use the `LangChainDocsQA` tool to look up information about building a custom agent in LangChain.\u001b[0mTop similarity score: 0.8702672719955444\n",
      "RAG fallback reason: Low similarity score — falling back to web search\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mI couldn't find a definitive answer in my local documents, so here's what I found online:\n",
      "['Customs brokers are private individuals, partnerships, associations or corporations licensed, regulated and empowered by U.S. Customs and Border ...', 'a person or company that is paid to make sure that all necessary taxes are paid and rules are followed so that goods can be imported into a country:.', 'A custom broker helps the buyer and seller during the import and export process, while the Custom Agent is working on behalf of the government ...', 'What is a licensed customs agent? A licensed customs agent is a person whose profession consists in fulfilling the customs formalities for a third party.', 'This notebook goes through how to create your own custom agent. In this example, we will use OpenAI Tool Calling to create this agent.', 'A customs agent is a law enforcement office working on behalf of the government to carry out inspections on goods and people moving in and out of a country.', 'Steps for Becoming a Customs Agent · Attend a degree program or gain experience in a related field. · Apply on the US Customs and Border Protection website.', 'Custom agents enable you to extend and personalize your monitoring capabilities beyond the standard agents provided in Demandbase One for...', 'Custom brokers or Customs House Brokerages are working positions that may be employed by or affiliated with freight forwarders, independent businesses, ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"To build a custom agent in LangChain, you can follow the steps outlined in this notebook, which uses OpenAI Tool Calling to create the agent.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHere is my response:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"LangChainDocsQA\",\n",
      "    \"action_input\": \"What is LangChain?\"\n",
      "}\n",
      "```\n",
      "\n",
      "This will ask the user to use the `LangChainDocsQA` tool to look up information about LangChain, and provide a direct answer.\u001b[0mTop similarity score: 0.4116864800453186\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mSounds like a plan!\n",
      "\n",
      "To answer what LangChain is, let's break it down step by step.\n",
      "\n",
      "**Step 1: Understand the Context**\n",
      "LangChain seems to be related to language or programming, possibly in an AI context. This makes me wonder if it's a framework, library, or tool for building models or interacting with them.\n",
      "\n",
      "**Step 2: Research Possible Definitions**\n",
      "After some quick searching, I found that LangChain is actually a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "\n",
      "**Step 3: Explore Key Features and Use Cases**\n",
      "LangChain likely offers features such as:\n",
      "\n",
      "* Easy composition of conversational flows\n",
      "* Support for various input/output formats (e.g., text, audio)\n",
      "* Integration with popular AI frameworks and libraries\n",
      "\n",
      "Use cases might include building chatbots for customer service, creating voice assistants for smart homes, or developing interactive stories.\n",
      "\n",
      "**Step 4: Confirm the Definition**\n",
      "After this step-by-step analysis, I'm fairly confident that LangChain is a framework for developing applications powered by large language models (LLMs).\n",
      "\n",
      "Sources:\n",
      "- https://python.langchain.com/docs/integrations/llms/ollama\n",
      "- https://python.langchain.com/docs/integrations/llms/ollama\n",
      "- https://python.langchain.com/docs/get_started/introduction\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Here's my response:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment. The framework offers features such as easy composition of conversational flows, support for various input/output formats, and integration with popular AI frameworks and libraries. Use cases include building chatbots for customer service, creating voice assistants for smart homes, or developing interactive stories.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0m\n",
      "Observation: force\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Here's my response:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": Sorry, it seems like the previous conversation got lost in space. Let me try again! LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0m\n",
      "Observation: force\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: ```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": Sorry, it seems like we're stuck in an infinite loop! Let me try again! LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0m\n",
      "Observation: force\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: ```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": It seems like we're experiencing some technical difficulties! Let me try again! LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0m\n",
      "Observation: force\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: ```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0m\n",
      "Observation: force\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: ```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0m\n",
      "Observation: force\n",
      "Thought:Agent error: variable agent_scratchpad should be a list of base messages, got Here is my response:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"LangChainDocsQA\",\n",
      "    \"action_input\": \"What is LangChain?\"\n",
      "}\n",
      "```\n",
      "\n",
      "This will ask the user to use the `LangChainDocsQA` tool to look up information about LangChain, and provide a direct answer.\n",
      "Observation: Sounds like a plan!\n",
      "\n",
      "To answer what LangChain is, let's break it down step by step.\n",
      "\n",
      "**Step 1: Understand the Context**\n",
      "LangChain seems to be related to language or programming, possibly in an AI context. This makes me wonder if it's a framework, library, or tool for building models or interacting with them.\n",
      "\n",
      "**Step 2: Research Possible Definitions**\n",
      "After some quick searching, I found that LangChain is actually a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "\n",
      "**Step 3: Explore Key Features and Use Cases**\n",
      "LangChain likely offers features such as:\n",
      "\n",
      "* Easy composition of conversational flows\n",
      "* Support for various input/output formats (e.g., text, audio)\n",
      "* Integration with popular AI frameworks and libraries\n",
      "\n",
      "Use cases might include building chatbots for customer service, creating voice assistants for smart homes, or developing interactive stories.\n",
      "\n",
      "**Step 4: Confirm the Definition**\n",
      "After this step-by-step analysis, I'm fairly confident that LangChain is a framework for developing applications powered by large language models (LLMs).\n",
      "\n",
      "Sources:\n",
      "- https://python.langchain.com/docs/integrations/llms/ollama\n",
      "- https://python.langchain.com/docs/integrations/llms/ollama\n",
      "- https://python.langchain.com/docs/get_started/introduction\n",
      "Thought:Could not parse LLM output: Here's my response:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment. The framework offers features such as easy composition of conversational flows, support for various input/output formats, and integration with popular AI frameworks and libraries. Use cases include building chatbots for customer service, creating voice assistants for smart homes, or developing interactive stories.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Observation: force\n",
      "Thought:Could not parse LLM output: Here's my response:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": Sorry, it seems like the previous conversation got lost in space. Let me try again! LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Observation: force\n",
      "Thought:Could not parse LLM output: ```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": Sorry, it seems like we're stuck in an infinite loop! Let me try again! LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Observation: force\n",
      "Thought:Could not parse LLM output: ```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": It seems like we're experiencing some technical difficulties! Let me try again! LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Observation: force\n",
      "Thought:Could not parse LLM output: ```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Observation: force\n",
      "Thought:Could not parse LLM output: ```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": LangChain is a framework for developing applications powered by large language models (LLMs). It simplifies every stage of the LLM application lifecycle: development, productionization, and deployment.\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Observation: force\n",
      "Thought:\n",
      "\n",
      "I now need to return a final answer based on the previous steps: of type <class 'str'>\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHere is my response:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"LangChainDocsQA\",\n",
      "    \"action_input\": \"What is LangChain?\"\n",
      "}\n",
      "```\n",
      "\n",
      "This will ask the user to use the `LangChainDocsQA` tool to look up information about LangChain, and provide a direct answer.\u001b[0mTop similarity score: 0.4116864800453186\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "# ___ Gradio Interface ____\n",
    "def agent_chat(message , chat_history):\n",
    "    try:\n",
    "        bot_message = agent_executor.run(message)\n",
    "    except Exception as e:\n",
    "        print(f\"Agent error: {e}\")\n",
    "        bot_message = \"An internal error occurred.\"\n",
    "    return bot_message\n",
    "\n",
    "iface = gr.ChatInterface(\n",
    "    fn=agent_chat,\n",
    "    title=\"LangChain RAG Chatbot\",\n",
    "    description=\"Ask LangChain questions with local RAG and web fallback.\",\n",
    "    examples=[ \n",
    "        \"How do I build a custom agent in LangChain?\",\n",
    "        \"What are the key features of llama3?\",\n",
    "        \"What's 2 to the power of 20 in Python?\",\n",
    "        \"Give me an intro to LangChain.\",\n",
    "        \"What is the capital of France?\",\n",
    "        \"Currnet US president?\",\n",
    "        \"What is the fastest growing religion in the world?\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch(share=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd949bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation Memory:\n",
      "{'chat_history': [HumanMessage(content='How do I build a custom agent in LangChain?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Unfortunately, it seems that LangChain is not related to customs brokers or agents. The provided information appears to be about customs brokers and their services. If you're looking for information on building a custom agent in LangChain, I couldn't find any relevant information.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='How do I build a custom agent in LangChain?', additional_kwargs={}, response_metadata={}), AIMessage(content='To build a custom agent in LangChain, you can follow the steps outlined in this notebook: [insert link to notebook]. This will guide you through creating your own custom agent using OpenAI Tool Calling.', additional_kwargs={}, response_metadata={}), HumanMessage(content='How do I build a custom agent in LangChain?', additional_kwargs={}, response_metadata={}), AIMessage(content='To build a custom agent in LangChain, you can use the `AgentExecutor` class and define your own custom tool by inheriting from the `Tool` class. You would then put your custom logic in the `run` method of the tool.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What are the key features of llama3?', additional_kwargs={}, response_metadata={}), AIMessage(content='The key features of LLaMA-3 include its ability to generate human-like text, perform tasks such as answering questions and summarizing long pieces of text, and its potential applications in areas like customer service and content creation.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"What's 2 to the power of 20 in Python?\", additional_kwargs={}, response_metadata={}), AIMessage(content='1,048,576', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the fastest growing religion in the world?', additional_kwargs={}, response_metadata={}), AIMessage(content='According to current trends, Islam is expected to surpass Christianity in terms of population by the second half of this century.', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConversation Memory:\")\n",
    "print(agent_executor.memory.load_memory_variables({}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
